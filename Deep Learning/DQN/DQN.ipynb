{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DQN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "37rTtwOt2VMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd,adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKAGJ-z2VMT",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YukXXckk2VMU",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z73cCmb2VMV",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOEf18JS2VMW",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3-IXsu2VMW",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETi26jfa2VMY",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjizifa2VMa",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9AK3o5e2VMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4YmV0lc2VMe",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhglPV842VMf",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdV96aA52VMg",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Y7ivRQ2VMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czFvTRFf2VMk",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8XyDdJd69R",
        "colab_type": "text"
      },
      "source": [
        "The function act selects an action using the learned policy with probability $1-\\epsilon$ and a random action with probability $\\epsilon$. Using random actions with a low probability is essential in order to explorate the environnement. However, the model might always enters the same states and miss better options. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnXsXR1E2VMm",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyQc9hge2VMn",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiYeobxF2VMo",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gFqdLcBqVBj",
        "colab_type": "text"
      },
      "source": [
        "## Environnement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vldFZYn-2VMp",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0hondyV2VMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YelMBpOJ2VMt",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr5nKzuQ2VMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=10 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjCtifuH2VM2",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1iOcvux2VM3",
        "colab_type": "text"
      },
      "source": [
        "Position represents the frame with value 1 where the rat is currently and -1 where the rat cannot go i.e on the two fisrt/last columns and 2 first/last lines in order to always have a 5x5 vue. \n",
        "board represents all the reward. When the rat access a certain position, it gets the reward associated with this position which is therefore set to 0 for the future. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqUxONY72VM3",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul9u49FU2VM4",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkxrDQWg2VM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(self.n_action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0fvhuQp2VM7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj27GBCX2VM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        win , lose = 0,0\n",
        "        state = env.reset()\n",
        "        game_over = False\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "              \n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)   \n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkOQZotA2VNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "c3484f34-1198-40ab-9a5a-1f3fa2cfc53b"
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.0/13.0. Average score (-3.0)\n",
            "Win/lose count 11.5/17.0. Average score (-4.25)\n",
            "Win/lose count 9.0/13.0. Average score (-4.166666666666667)\n",
            "Win/lose count 11.0/22.0. Average score (-5.875)\n",
            "Win/lose count 9.0/18.0. Average score (-6.5)\n",
            "Win/lose count 11.0/21.0. Average score (-7.083333333333333)\n",
            "Win/lose count 8.5/8.0. Average score (-6.0)\n",
            "Win/lose count 13.5/13.0. Average score (-5.1875)\n",
            "Win/lose count 8.0/11.0. Average score (-4.944444444444445)\n",
            "Win/lose count 8.5/17.0. Average score (-5.3)\n",
            "Final score: -5.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmMJykGl2VNF",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBR0cznE2VNG",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlbF9COV2VNH",
        "colab_type": "text"
      },
      "source": [
        "First, \n",
        "\n",
        "\\begin{align*}\n",
        "Q_{\\pi}(s,a) & =\\mathbb{E}_{p_{\\pi}}\\left(\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right)\\\\\n",
        " & =\\mathbb{E}_{p_{\\pi}}\\left(r(s_{0},a_{0})+\\sum_{t=1}^{T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right)\\\\\n",
        " & =r(s,a)+\\mathbb{E}_{p_{\\pi}}\\left(\\sum_{t=1}^{T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right)\\\\\n",
        " & =r(s,a)+\\gamma\\sum_{s',a'}\\left[\\mathbb{E}_{p_{\\pi}}\\left(\\sum_{t=1}^{T}\\gamma^{t-1}r(s_{t},a_{t})|s_{0}=s,a_{0}=a,s_{1}=s',a_{1}=a'\\right)p_{\\pi}(s_{1}=s',a_{1}=a'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & =r(s,a)+\\gamma\\sum_{s',a'}\\left[\\mathbb{E}_{p_{\\pi}}\\left(\\sum_{t=1}^{T}\\gamma^{t-1}r(s_{t},a_{t})|s_{1}=s',a_{1}=a'\\right)p_{\\pi}(s_{1}=s',a_{1}=a'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & =r(s,a)+\\gamma\\sum_{s',a'}\\left[\\mathbb{E}_{p_{\\pi}}\\left(\\sum_{t=0}^{T}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{1}=s',a_{1}=a'\\right)p_{\\pi}(s_{1}=s',a_{1}=a'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & \\text{car }T=\\infty\\\\\n",
        " & =r(s,a)+\\gamma\\sum_{s',a'}\\left[Q_{\\pi}(s',a')p_{\\pi}(s_{1}=s',a_{1}=a'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & \\text{On peut poser la suite  }\\tilde{s}_{t}=s_{t+1}\\text{ et }\\tilde{a}_{t}=a_{t+1}\\\\\n",
        " & =r(s,a)+\\gamma\\mathbb{E}_{(s',a')\\sim p(.,.|s,a)}\\left[Q_{\\pi}(s',a')\\right]\n",
        "\\end{align*}\n",
        "\n",
        "Then \n",
        "\n",
        "\\begin{align*}\n",
        "Q^{*}(s,a) & =max_{\\pi}Q_{\\pi}(s,a)\\\\\n",
        " & =max_{\\pi}\\left[r(s,a)+\\gamma\\mathbb{E}_{(s',a')\\sim p(.,.|s,a)}\\left[Q_{\\pi}(s',a')\\right]\\right]\\\\\n",
        " & =r(s,a)+\\gamma max_{\\pi}\\left[\\sum_{s',a'}\\left[Q_{\\pi}(s',a')p_{\\pi}(s_{1}=s',a_{1}=a'|s_{0}=s,a_{0}=a)\\right]\\right]\\\\\n",
        " & =r(s,a)+\\gamma max_{\\pi}\\left[\\sum_{s',a'}\\left[Q_{\\pi}(s',a')\\pi(a'|s')p(s_{1}=s'|s_{0}=s,a_{0}=a)\\right]\\right]\\\\\n",
        " & =r(s,a)+\\gamma\\left[\\sum_{s'}max_{\\pi}\\mathbb{E}_{a'\\sim\\pi(.|s')}\\left[Q_{\\pi}(s',a')\\right]p(s_{1}=s'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & =(s,a)+\\gamma\\left[\\sum_{s'}max_{a'}Q^{*}(s',a')p(s_{1}=s'|s_{0}=s,a_{0}=a)\\right]\\\\\n",
        " & =r(s,a)+\\gamma\\mathbb{E}_{s'\\sim p^{*}(s,a)}\\left[Q^{*}(s',a')\\right]\n",
        "\\end{align*}\n",
        "\n",
        "Finaly,\n",
        "\n",
        "We can consider for the loss the norm of the difference between $Q^{*}(s,a)$\n",
        "as computed above and $Q(s,a,\\theta)$ i.e.\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJN4ZZqq2VNH",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AjkmvGj2VNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "      if len(self.memory) > self.max_memory:\n",
        "        del self.memory[0]\n",
        "      self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        rand = np.random.randint(len(self.memory))\n",
        "        return self.memory[rand]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxqo62ag2VNK",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P05gqMLk2VNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        \n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCLYsUFm2VNN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2qd06bV2VNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape(1,5,5,self.n_state))[0])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "\n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        for i in range(self.batch_size):\n",
        "            ######## FILL IN\n",
        "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
        "            input_states[i] = s_\n",
        "            if game_over_:\n",
        "                ######## FILL IN\n",
        "                # We want the loss on the direction of the 3 actions not tested here to be zero so that the model doesn't learn on these unknown values. \n",
        "                # so we set the target_q equals to the prediction so that mse = 0 for these actions\n",
        "                target_q[i] = self.model.predict(s_.reshape(1,5,5,self.n_state))[0]\n",
        "                # for the action used, we use only the reward here\n",
        "                target_q[i][a_] = r_\n",
        "            else:\n",
        "                ######## FILL IN\n",
        "                # same as above\n",
        "                target_q[i] = self.model.predict(s_.reshape(1,5,5,self.n_state))[0]\n",
        "                # for the action used, we use the Q formula\n",
        "                target_q[i][a_] = r_ + self.discount* np.max(self.model.predict(n_s_.reshape(1,5,5,self.n_state))[0])\n",
        "\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        ####### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((5*5*self.n_state,)))\n",
        "        model.add(Dense(32, input_shape=(5*5*self.n_state,)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dense(20))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        #model.add(Activation('relu'))\n",
        "\n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYev1ch2Die6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we could also use this loss without needing to modify the q_target for unused action\n",
        "# I finaly don't use it \n",
        "\n",
        "import keras.backend as K \n",
        "def custom_loss(y_pred,y_true):\n",
        "  y_pred_aux = (y_true>0)*y_pred\n",
        "  loss = K.mean(K.sum(K.square(y_pred_aux - y_true),axis = 1), axis=0)\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JOyLjlK2VNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3f98d555-d0de-4b5c-ef46-423d9662dddb"
      },
      "source": [
        "epochs_train = 21\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.01, epsilon = 0.1, memory_size=1000, batch_size = 100)\n",
        "train(agent, env, epochs_train, prefix='fc_train')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/021 | Loss 0.0148 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 001/021 | Loss 0.0329 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 002/021 | Loss 0.0284 | Win/lose count 4.5/8.0 (-3.5)\n",
            "Epoch 003/021 | Loss 0.0018 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 004/021 | Loss 0.0031 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 005/021 | Loss 0.0022 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 006/021 | Loss 0.0026 | Win/lose count 7.0/6.0 (1.0)\n",
            "Epoch 007/021 | Loss 0.0018 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 008/021 | Loss 0.0202 | Win/lose count 6.0/9.0 (-3.0)\n",
            "Epoch 009/021 | Loss 0.0439 | Win/lose count 11.0/5.0 (6.0)\n",
            "Epoch 010/021 | Loss 0.0041 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 011/021 | Loss 0.0191 | Win/lose count 8.0/6.0 (2.0)\n",
            "Epoch 012/021 | Loss 0.0230 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 013/021 | Loss 0.0177 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 014/021 | Loss 0.0024 | Win/lose count 3.5/6.0 (-2.5)\n",
            "Epoch 015/021 | Loss 0.0018 | Win/lose count 7.5/2.0 (5.5)\n",
            "Epoch 016/021 | Loss 0.0012 | Win/lose count 8.5/5.0 (3.5)\n",
            "Epoch 017/021 | Loss 0.0011 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 018/021 | Loss 0.0270 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 019/021 | Loss 0.0012 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 020/021 | Loss 0.0021 | Win/lose count 10.5/2.0 (8.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po-9d7vr_hPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "3c25de7f-9ade-4d3c-e1cd-a7925d019e68"
      },
      "source": [
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR6y3cSU2VNV",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MCvv0zm2VNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        ###### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),\n",
        "                        activation='relu',\n",
        "                        input_shape=(5,5,self.n_state)))\n",
        "        model.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        #model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dense(30, activation='relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        print(model.summary())\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3WSXsaL2VNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "119ed220-5788-428e-a56f-703c40848e35"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "epochs_train = 21\n",
        "agent = DQN_CNN(size, lr=.01, epsilon = 0.1, memory_size=2000, batch_size = 100)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 3, 3, 64)          1216      \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 2, 2, 64)          16448     \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 30)                7710      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 4)                 124       \n",
            "=================================================================\n",
            "Total params: 25,498\n",
            "Trainable params: 25,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 000/021 | Loss 0.0011 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 001/021 | Loss 0.0125 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 002/021 | Loss 0.0043 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 003/021 | Loss 0.0010 | Win/lose count 1.0/4.0 (-3.0)\n",
            "Epoch 004/021 | Loss 0.0245 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 005/021 | Loss 0.0020 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 006/021 | Loss 0.0027 | Win/lose count 7.5/5.0 (2.5)\n",
            "Epoch 007/021 | Loss 0.0007 | Win/lose count 7.5/2.0 (5.5)\n",
            "Epoch 008/021 | Loss 0.0013 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 009/021 | Loss 0.0026 | Win/lose count 11.0/3.0 (8.0)\n",
            "Epoch 010/021 | Loss 0.0008 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 011/021 | Loss 0.0213 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 012/021 | Loss 0.0014 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 013/021 | Loss 0.0010 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 014/021 | Loss 0.0014 | Win/lose count 11.5/2.0 (9.5)\n",
            "Epoch 015/021 | Loss 0.0007 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 016/021 | Loss 0.0010 | Win/lose count 11.5/2.0 (9.5)\n",
            "Epoch 017/021 | Loss 0.0015 | Win/lose count 18.0/4.0 (14.0)\n",
            "Epoch 018/021 | Loss 0.0011 | Win/lose count 8.5/5.0 (3.5)\n",
            "Epoch 019/021 | Loss 0.0010 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 020/021 | Loss 0.0129 | Win/lose count 4.5/4.0 (0.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAF0ltZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAM9ZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpJw4v/ApLdW+BTLYTkVLnX1aIxw4jw34T+sr5nf6CxMUuUUsv/aQCOZ3Mgp9xkC79cjSRGIOh/scJyoZlDNEE70PwlqfGS8f01HQ/CShOhtaJ4fHedb0KsSB/umn1mHUN5QljjY7BCsa2QRXAWYJH5+f+OY+xxx/a6T3T1Qcl5o4+CHKEOTElGfMJo94NMcqdulJemEHBSqytS1G1xtaZX7dtUtoU/wj5EDoDlFiicV4/J/d/hFqXg28khYvZpryGppp936u0GdMHGOG8ULb14l0bN5F6jDlrBIf3PaOP5N4o4wFtBi0dFoJACkVL/1u2xSkAsDWGfwV8UDNYPkpb7hqgLXIL11YqmWUofVXqqIzibY/1lQEdN2jwb0icaV2FuVwtnFAhXP76z3t98r1mCWsfH9JSlAjmiDxBX5qtLmmC4cIXw+sKk5ncc6lKxAeCjgb8+ScDUhcOzr8kQAvU10nee2MuI0gIkUiDuyboxSbU0rrI9KISnuz27WT/qaNZIVhIbHpkUMPZPL1aeU3iMITjcAkiR5Ui2SedQXK/Ym5L4bpQ3f3Ux+mYxZagVTe36uhdkVcJVwALkZiQ0WM4SoNQY8mHS+NYxO270iwxHMow43iI+dcimiWAnkfbK4YMiB1W/aLKbLAjvjkag8Ynm4CgNtxtqfK0bDjxBIYTVVOaUxtYg3PAR6fDrSY/tYxU6DUqGWHGsWtoaJpX8iMOcTuouQqJiVnd602vaJf4gCx2AGTOdVg9ZNdRQABZ8AcTuiYq0dxuwuAhemiXDdIpOUiGT8C07yihuKwAAlHE5yPILXMdWfmMp17rLODsbwWJP9Mdyn1tdB4rlAlD7kSqauGIhnT280h+MUHV7cb/i5GWRHP2q0AXMSAfIqGsfVgSAbcdP2fQHmGzYKXqGdBCOVsYifcWdDIjk0AFdleYiYPJVzgJstW9rDosWDhzRcYZB9MkIUEE8rUT1Fs/zgrHHhm6yh/tKuxCRoItMZLAxqE/c8HRRn4UdK2QQ98HtBgACFgQAAABVBmiNsQ3/+p4QAEtM+qa262cZBtPgAAAANQZ5BeIV/AA8wK4bxwQAAAA8BnmJqQr8ADt2BLlf4VMAAAAAdQZplSahBaJlMFPDf/qeEABxvYPXs1TWbbx5vDV8AAAAQAZ6EakK/ABdFGiZE0rO5QQAAABlBmoZJ4QpSZTAhv/6nhAArHon+q3zH4k3BAAAAGUGap0nhDomUwId//qmWACEIsN0YhHPsFOEAAAApQZrLSeEPJlMCG//+p4QASb5IrnMsrnvH4FKls/ApnYE9r/RwI8MkTIAAAAAfQZ7pRRE8L/8ALFPrfllcyymKMcywDwcyyDhAT+H1oAAAAA8Bnwh0Qr8AOLFJjeoI14sAAAAQAZ8KakK/ADtsweS5nyUZgAAAABdBmw1JqEFomUwU8N/+p4QAL7dSt0W8fAAAAA8BnyxqQr8AO3YEuV/gDMEAAAASQZsvSeEKUmUwUsN//qeEAAEnAAAAEgGfTmpCvwA7XOKQbBl79ZWGYQAAABJBm1FJ4Q6JlMFEw3/+p4QAAScAAAARAZ9wakK/ADtTrNfCKSw4uAwAAAASQZtzSeEPJlMFPDf//qeEAAEnAAAAEQGfkmpCvwA7U6zXwiksOLgMAAAAEkGblUnhDyZTBTw3//6nhAABJwAAABEBn7RqQr8AO1Os18IpLDi4DQAAABJBm7dJ4Q8mUwU8N//+p4QAAScAAAARAZ/WakK/ADtTrNfCKSw4uA0AAAASQZvZSeEPJlMFPDf//qeEAAEnAAAAEQGf+GpCvwA7U6zXwiksOLgMAAAAEkGb+0nhDyZTBTw3//6nhAABJwAAABEBnhpqQr8AO1Os18IpLDi4DAAAABJBmh1J4Q8mUwU8N//+p4QAAScAAAARAZ48akK/ADtTrNfCKSw4uA0AAAAWQZohSeEPJlMCG//+p4QAS746fa62gAAAAA5Bnl9FETwv/wAtdAQYsAAAABEBnn50Qr8AO01zB6Cet1lYZwAAABABnmBqQr8APMrg12JeBVwIAAAAGUGaYkmoQWiZTAhv//6nhABLUvaOV9JboEEAAAAZQZqDSeEKUmUwId/+qZYAJj8efv2QbioP4AAAABJBmqdJ4Q6JlMCHf/6plgAAlYEAAAAMQZ7FRRE8L/8AALKBAAAADwGe5HRCvwAo9o7o7b4WHwAAAA8BnuZqQr8AJ1ZRus9We/MAAAATQZrrSahBaJlMCHf//qmWAACVgAAAAAxBnwlFESwv/wAAsoAAAAAPAZ8odEK/ACj2jujtvhYfAAAADwGfKmpCvwAnVlG6z1Z78wAAABNBmy9JqEFsmUwId//+qZYAAJWAAAAADEGfTUUVLC//AACygQAAAA8Bn2x0Qr8AKPaO6O2+Fh8AAAAPAZ9uakK/ACdWUbrPVnvzAAAAGkGbckmoQWyZTAh3//6plgAmCLDdGIRz7A/gAAAAEkGfkEUVLCv/ADzM76FuSKrZgAAAABABn7FqQr8APMzB5MD17imBAAAAGUGbtUmoQWyZTAh3//6plgAmPx5+/3HosoAAAAASQZ/TRRUsK/8APMC851k+TgOAAAAADgGf9GpCvwA81fTgbUk9AAAAE0Gb+UmoQWyZTAh3//6plgAAlYAAAAAMQZ4XRRUsL/8AALKBAAAADwGeNnRCvwAo9o7o7b4WHwAAAA8BnjhqQr8AJ1ZRus9We/MAAAATQZo9SahBbJlMCHf//qmWAACVgQAAAAxBnltFFSwv/wAAsoAAAAAPAZ56dEK/ACj2jujtvhYfAAAADwGefGpCvwAnVlG6z1Z78wAAABNBmmFJqEFsmUwId//+qZYAAJWAAAAADEGen0UVLC//AACygAAAAA8Bnr50Qr8AKPaO6O2+Fh8AAAAPAZ6gakK/ACdWUbrPVnvzAAAAE0GapUmoQWyZTAh3//6plgAAlYEAAAAMQZ7DRRUsL/8AALKAAAAADwGe4nRCvwAo9o7o7b4WHwAAAA8BnuRqQr8AJ1ZRus9We/MAAAATQZrpSahBbJlMCHf//qmWAACVgQAAAAxBnwdFFSwv/wAAsoEAAAAPAZ8mdEK/ACj2jujtvhYfAAAADwGfKGpCvwAnVlG6z1Z78wAAABNBmy1JqEFsmUwId//+qZYAAJWBAAAADEGfS0UVLC//AACygAAAAA8Bn2p0Qr8AJ1ZRxHZdlicAAAAPAZ9sakK/ACjqNEFqPLvpAAAAE0GbcUmoQWyZTAh3//6plgAAlYEAAAAMQZ+PRRUsL/8AALKBAAAADwGfrnRCvwAnVlHEdl2WJwAAAA8Bn7BqQr8AKOo0QWo8u+kAAAAnQZu1SahBbJlMCG///qeEAEm+SK5zLK57x+BSpbPwKZ2BjbrF+hIPAAAAEEGf00UVLC//ACxUCK0opcwAAAAPAZ/ydEK/ACfRhAZJcxOAAAAAEAGf9GpCvwA7bPmN0OSDkDkAAAAaQZv3SahBbJlMFEw3//6nhABJvo5+SLcNXvwAAAAQAZ4WakK/ADzK4NceKtpeIQAAABlBmhhJ4QpSZTAh3/6plgAZSCyuM0v7YETBAAAAIkGaPEnhDomUwIb//qeEADJ+wf577DOVfddqrmWWJkdzg3QAAAAWQZ5aRRE8L/8AHa/itpXK5DTuTs9d4QAAABABnnl0Qr8AKOnUnlfkptwQAAAAEAGee2pCvwAbpm5rjxVtSuEAAAASQZpgSahBaJlMCG///qeEAAEnAAAADEGenkURLC//AACygAAAAA8Bnr10Qr8AEaVI4jsuy8kAAAAPAZ6/akK/ABGlSN1nqz8vAAAAKEGaokmoQWyZTBRMN//+p4QAIN8OfMsrxhn4FMtnZ8ChSXbrzPP9rOsAAAAQAZ7BakK/ABsHbhNxn16hdQAAABpBmsNJ4QpSZTAhv/6nhAAg30ugx+8+C264MwAAABlBmudJ4Q6JlMCGf/6eEACCof407vEP3YYrAAAAEEGfBUURPC//ABR6DZ54zuEAAAAPAZ8kdEK/ABpklEKYI1uBAAAAEAGfJmpCvwAbp1TyXM+S5oEAAAAYQZsoSahBaJlMCGf//p4QAM3IY5+l/cqBAAAAGUGbSUnhClJlMCG//qeEAFG9E/1W+Y/EUkAAAAAYQZtqSeEOiZTAhv/+p4QAU/FaQQif5bcrAAAAE0GbjEnhDyZTBRE8N//+p4QAAScAAAAQAZ+rakK/AENzRvgPA/LdsAAAABJBm65J4Q8mUwU8N//+p4QAAScAAAAQAZ/NakK/AENtc4XSSkxdsQAAABNBm9BJ4Q8mUwU8O//+qZYAAJWBAAAAEAGf72pCvwBDbXOF0kpMXbAAAAAWQZv0SeEPJlMCG//+p4QAVr3U/a6ggAAAAA5BnhJFETwv/wAzirbZ8QAAABABnjF0Qr8AQ4QGwZxicW7YAAAAEAGeM2pCvwBFc0bz1LwKtTAAAAAeQZo4SahBaJlMCGf//p4QAwshtb/DnxAUz9WUPNgdAAAAEEGeVkURLC//AHbTmlWpxGoAAAAYAZ51dEK/AEShKx8JSp//xCA5J/8sq1qZAAAAEAGed2pCvwCj2PHK/tw+oEEAAAAZQZp5SahBbJlMCG///qeEATRAFm2MUJRJwAAAABhBmppJ4QpSZTAhv/6nhAJh0T/T/KnqpIEAAAAbQZq7SeEOiZTAh3/+qZYF4TDdD+CkgcP6olDAAAAAFkGa30nhDyZTAh3//qmWBtcgzPbYKGEAAAAOQZ79RRE8L/8CAR+cVMEAAAAPAZ8cdEK/Aq9x3SEtxaGLAAAAEAGfHmpCvwKDYt1r8fbgrYAAAAATQZsDSahBaJlMCHf//qmWAACVgQAAAAxBnyFFESwv/wAAsoAAAAAQAZ9AdEK/AoNi3XcA+3BWwQAAABABn0JqQr8Cg2Lda/H24K2AAAAAE0GbR0moQWyZTAh3//6plgAAlYEAAAAMQZ9lRRUsL/8AALKBAAAAEAGfhHRCvwKDYt13APtwVsEAAAAQAZ+GakK/AoNi3Wvx9uCtgQAAABJBm4tJqEFsmUwIb//+p4QAAScAAAAMQZ+pRRUsL/8AALKAAAAAEAGfyHRCvwKDYt13APtwVsEAAAAQAZ/KakK/AoNi3Wvx9uCtgAAAABxBm8xJqEFsmUwId//+qZYGH0ugcP8SJh0eymDAAAAAG0Gb8EnhClJlMCHf/qmWBtJZi0zPdTdpfXGW0QAAABBBng5FNEwv/wIB3x3Oe2LhAAAADwGeLXRCvwGJSUQpgiypgQAAAA8Bni9qQr8Cr2I8mA33JccAAAAYQZo0SahBaJlMCHf//qmWBtk5u9KgEzZgAAAAEEGeUkURLC//AgHfHc57YuEAAAAPAZ5xdEK/Aq7QgMkqsO6AAAAAEAGec2pCvwKuT5zrM/BOuIAAAAATQZp4SahBbJlMCHf//qmWAACVgQAAAAxBnpZFFSwv/wAAsoAAAAAQAZ61dEK/ApJAHP10DiyRgQAAABABnrdqQr8CkNa7qq89EtaBAAAAHkGavEmoQWyZTAhv//6nhAnr8KNZtXDsrA4f54xoQAAAABBBntpFFSwv/wHV+9fkNFNBAAAAEAGe+XRCvwKSQBztjE2qSsAAAAAPAZ77akK/AnbQOMD8sG3BAAAAGUGa/UmoQWyZTAh3//6plgXdnOtGj/dOAUkAAAASQZsBSeEKUmUwId/+qZYAAJWAAAAADEGfP0U0TC//AACygAAAAA8Bn150Qr8Cr3HdIS3FoYsAAAAQAZ9AakK/AoNi3Wvx9uCtgAAAABJBm0VJqEFomUwIb//+p4QAAScAAAAMQZ9jRREsL/8AALKAAAAAEAGfgnRCvwKDYt13APtwVsEAAAAQAZ+EakK/AoNi3Wvx9uCtgQAAABxBm4ZJqEFsmUwId//+qZYGH0ugcP8SJh0eymDBAAAAEkGbqknhClJlMCHf/qmWAACVgQAAAAxBn8hFNEwv/wAAsoAAAAAQAZ/ndEK/AYTOTiOy7KjugAAAAA8Bn+lqQr8BkwWNErnl0ZUAAAATQZvuSahBaJlMCHf//qmWAACVgAAAABRBngxFESwv/wIA3nTOK1bi11FVMAAAAA8Bnit0Qr8Cr81QOm5fkQcAAAAQAZ4takK/Aq5PnOsz8E64gQAAABNBmjJJqEFsmUwId//+qZYAAJWBAAAADEGeUEUVLC//AACygAAAABABnm90Qr8CkkAc/XQOLJGAAAAAEAGecWpCvwKQ1ruqrz0S1oEAAAATQZp2SahBbJlMCHf//qmWAACVgAAAAAxBnpRFFSwv/wAAsoAAAAAQAZ6zdEK/ApJAHP10DiyRgQAAAA8BnrVqQr8BkwWNErnl0ZUAAAATQZq6SahBbJlMCHf//qmWAACVgQAAABRBnthFFSwv/wIA3nTOK1bi11FVMQAAAA8Bnvd0Qr8Cr81QOm5fkQcAAAAQAZ75akK/Aq5PnOsz8E64gQAAABNBmv5JqEFsmUwId//+qZYAAJWAAAAADEGfHEUVLC//AACygQAAABABnzt0Qr8CkkAc/XQOLJGBAAAAEAGfPWpCvwKQ1ruqrz0S1oAAAAASQZsiSahBbJlMCG///qeEAAEnAAAADEGfQEUVLC//AACygQAAABABn390Qr8CkkAc/XQOLJGAAAAAEAGfYWpCvwKQ1ruqrz0S1oEAAAASQZtmSahBbJlMCGf//p4QAAR8AAAADEGfhEUVLC//AACygQAAABABn6N0Qr8CkkAc/XQOLJGBAAAAEAGfpWpCvwKQ1ruqrz0S1oEAAAAaQZupS6hCEFskRggoB/IB/YeAIV/+OEAAEXEAAAAmQZ/HRRUsK/8Cr2Q8sYhqswqoWU0zbCEu1FoOitnOfcaev9snjRsAAAAiAZ/oakK/Aq9rgkC7cuQ0M8GandUaXmMzQKasMrYoEPHCYAAADDhtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAALYnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACtptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAqFbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAKRXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAGEGN0dHMAAAAAAAAAwAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAMAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAMAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABfIAAAAZAAAAEQAAABMAAAAhAAAAFAAAAB0AAAAdAAAALQAAACMAAAATAAAAFAAAABsAAAATAAAAFgAAABYAAAAWAAAAFQAAABYAAAAVAAAAFgAAABUAAAAWAAAAFQAAABYAAAAVAAAAFgAAABUAAAAWAAAAFQAAABoAAAASAAAAFQAAABQAAAAdAAAAHQAAABYAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAAB4AAAAWAAAAFAAAAB0AAAAWAAAAEgAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAArAAAAFAAAABMAAAAUAAAAHgAAABQAAAAdAAAAJgAAABoAAAAUAAAAFAAAABYAAAAQAAAAEwAAABMAAAAsAAAAFAAAAB4AAAAdAAAAFAAAABMAAAAUAAAAHAAAAB0AAAAcAAAAFwAAABQAAAAWAAAAFAAAABcAAAAUAAAAGgAAABIAAAAUAAAAFAAAACIAAAAUAAAAHAAAABQAAAAdAAAAHAAAAB8AAAAaAAAAEgAAABMAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAIAAAAB8AAAAUAAAAEwAAABMAAAAcAAAAFAAAABMAAAAUAAAAFwAAABAAAAAUAAAAFAAAACIAAAAUAAAAFAAAABMAAAAdAAAAFgAAABAAAAATAAAAFAAAABYAAAAQAAAAFAAAABQAAAAgAAAAFgAAABAAAAAUAAAAEwAAABcAAAAYAAAAEwAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAEwAAABcAAAAYAAAAEwAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAeAAAAKgAAACYAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSIo9rr02VNa",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwBYWtgg2VNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "d816761f-8644-4547-b703-1b84cfacf514"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.01, epsilon = 0, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.01, epsilon = 0, memory_size=2000, batch_size = 32)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 3, 3, 64)          1216      \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 2, 2, 64)          16448     \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 30)                7710      \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 4)                 124       \n",
            "=================================================================\n",
            "Total params: 25,498\n",
            "Trainable params: 25,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Test of the CNN\n",
            "Win/lose count 10.5/2.0. Average score (8.5)\n",
            "Win/lose count 5.0/2.0. Average score (5.75)\n",
            "Win/lose count 8.5/2.0. Average score (6.0)\n",
            "Win/lose count 15.0/2.0. Average score (7.75)\n",
            "Win/lose count 20.5/3.0. Average score (9.7)\n",
            "Win/lose count 5.5/4.0. Average score (8.333333333333334)\n",
            "Win/lose count 8.5/2.0. Average score (8.071428571428571)\n",
            "Win/lose count 4.5/3.0. Average score (7.25)\n",
            "Win/lose count 5.0/2.0. Average score (6.777777777777778)\n",
            "Win/lose count 3.0/0. Average score (6.4)\n",
            "Final score: 6.4\n",
            "Test of the FC\n",
            "Win/lose count 5.0/3.0. Average score (2.0)\n",
            "Win/lose count 3.5/1.0. Average score (2.25)\n",
            "Win/lose count 4.0/4.0. Average score (1.5)\n",
            "Win/lose count 1.0/2.0. Average score (0.875)\n",
            "Win/lose count 1.0/1.0. Average score (0.7)\n",
            "Win/lose count 7.0/5.0. Average score (0.9166666666666666)\n",
            "Win/lose count 4.5/1.0. Average score (1.2857142857142858)\n",
            "Win/lose count 8.5/2.0. Average score (1.9375)\n",
            "Win/lose count 0.5/2.0. Average score (1.5555555555555556)\n",
            "Win/lose count 3.5/2.0. Average score (1.55)\n",
            "Final score: 1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y056WqXC2VNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "8ffa75b4-2fae-49d3-e88d-e04a85ffef07"
      },
      "source": [
        "HTML(display_videos('cnn_test0.mp4'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1X6IKzD2VNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "606d0358-4a55-426f-8e98-80d967bea802"
      },
      "source": [
        "HTML(display_videos('fc_test0.mp4'))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRp3jmBy2VNi",
        "colab_type": "text"
      },
      "source": [
        "We observe that with both algorithms, the rat tends to stay in its position (by repeatedly going up and down for example) when it can't find a positive reward near. It doesn't try to explore in order to find rewards elsewhere. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu6m9d6g2VNi",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3w6gW1k7L40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    agent.set_epsilon(0)\n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        win , lose = 0,0\n",
        "        state = env.reset()\n",
        "        game_over = False\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action,train = False)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "              \n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)   \n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL_KbKar2VNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    #linear epsilons \n",
        "    #epsilons = np.linspace(1,0,epoch)\n",
        "    #exponential decreasing\n",
        "    epsilons = np.exp(-np.linspace(0,3,epoch))\n",
        "\n",
        "    for e in range(epoch):\n",
        "        #we set epsilon \n",
        "        agent.set_epsilon(epsilons[e])\n",
        "\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        \n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action,train):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCE3rdun2VNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "334e6c8c-ad87-4186-fd62-af2f8909950b"
      },
      "source": [
        "\n",
        "# Training\n",
        "epochs_train = 21\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.01, epsilon = 0.1, memory_size=2000, batch_size = 100,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore20.mp4'))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 3, 3, 64)          1792      \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 2, 2, 64)          16448     \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 30)                7710      \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 4)                 124       \n",
            "=================================================================\n",
            "Total params: 26,074\n",
            "Trainable params: 26,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 000/021 | Loss 0.0100 | Win/lose count 9.0/27.50000000000012 (-18.50000000000012)\n",
            "Epoch 001/021 | Loss 0.0040 | Win/lose count 10.0/27.50000000000007 (-17.50000000000007)\n",
            "Epoch 002/021 | Loss 0.0024 | Win/lose count 13.5/26.600000000000037 (-13.100000000000037)\n",
            "Epoch 003/021 | Loss 0.0029 | Win/lose count 9.5/24.4000000000001 (-14.900000000000102)\n",
            "Epoch 004/021 | Loss 0.0041 | Win/lose count 15.0/19.700000000000014 (-4.7000000000000135)\n",
            "Epoch 005/021 | Loss 0.0040 | Win/lose count 24.5/27.50000000000005 (-3.0000000000000497)\n",
            "Epoch 006/021 | Loss 0.0134 | Win/lose count 13.5/26.700000000000113 (-13.200000000000113)\n",
            "Epoch 007/021 | Loss 0.0048 | Win/lose count 17.0/19.700000000000035 (-2.700000000000035)\n",
            "Epoch 008/021 | Loss 0.0023 | Win/lose count 21.5/19.200000000000017 (2.299999999999983)\n",
            "Epoch 009/021 | Loss 0.0042 | Win/lose count 18.5/22.400000000000045 (-3.9000000000000448)\n",
            "Epoch 010/021 | Loss 0.0054 | Win/lose count 15.0/19.300000000000015 (-4.300000000000015)\n",
            "Epoch 011/021 | Loss 0.0026 | Win/lose count 21.5/12.19999999999998 (9.30000000000002)\n",
            "Epoch 012/021 | Loss 0.0044 | Win/lose count 14.0/14.899999999999967 (-0.8999999999999666)\n",
            "Epoch 013/021 | Loss 0.0040 | Win/lose count 20.0/15.59999999999997 (4.4000000000000306)\n",
            "Epoch 014/021 | Loss 0.0020 | Win/lose count 22.0/11.09999999999998 (10.90000000000002)\n",
            "Epoch 015/021 | Loss 0.0080 | Win/lose count 16.0/14.499999999999979 (1.5000000000000213)\n",
            "Epoch 016/021 | Loss 0.0021 | Win/lose count 16.5/17.89999999999999 (-1.3999999999999915)\n",
            "Epoch 017/021 | Loss 0.0029 | Win/lose count 15.0/17.59999999999999 (-2.5999999999999908)\n",
            "Epoch 018/021 | Loss 0.0028 | Win/lose count 10.5/16.799999999999972 (-6.299999999999972)\n",
            "Epoch 019/021 | Loss 0.0024 | Win/lose count 19.5/14.599999999999968 (4.900000000000032)\n",
            "Epoch 020/021 | Loss 0.0054 | Win/lose count 22.5/14.399999999999967 (8.100000000000033)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGKVtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMEZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz8ZS8pY/so8NEee+ToUdl8ClwFFfAppMj0u5TVCpKSVX1DjVdLqqYXdUrUjKERRmVJP9ckvJsB5QcttGlS1j671oJDuqvyyi5EysqVbL2LZaNbIDhMCGhOGAc8Kwhj0mOfDoHPalCOgQZ8l2GhcxYGa0ND67oJloQjwEgw1JeUNcy0j60uu8vH8VtLt+f9g0MVDVLnRAFYKk0PaL6OA8/PfTPWofaBGOkNqaJpUg4GDctMPVI0BD9o2W7xdOrsB8b5h4OSfVu08K3Nn3pvUJEgu1M+cVg9Yfxga8BasBv+/+8zVPQJpKvCldjwfxkopNQPMm9xVxBEsMAxKFpOtjkZjvfEfVXfJwC0FYfQqOuHa8OIkjZ84WdsrLN5x4ZuX2c92J000WQSgrckTRdIaUX3AYnHD78Fwjsy4LdrD6ACuvzdpcKAZo42YmeAup56V6/GCt0OL8zMwR+unLaTsk26p+2l/8Pg9RKdXmJpaHUbCDyBzJd/yPNX6KBvpIGszpMD4Bb9WtpOas1zC6kflZpDGibmhBuUibVgu/Rtvm3rsxGaVmHcbFySBqWYyDE7j/6A4WT+xVJK4x7udgtlEq+wkFIRsCIZbp/q2hJvWAOggqfcm3Pds7qMYOoQYMEKlOF5TjC49ST9gcgU+79v39obloXPo94DLlHQLoAB8pQg8/1hT814AHxWknyow1keY9qrSt1dn2iS94jnIcqhWm4v0ThK4K2GjAvBBTZ9RphHc0BhbJWP5uwcZp1RPoKmFIlYUKkYyeACtjFFFU0f6SgigigE+FXEuCeB310iOvh6wUlFLvu4KO+3ABb4CqaN0gKHGMGZBU4UW9WCdutg7Gd/8IPL2RDjj+3HEUMJAMcvFA1pD9UxLh1HHBpLRxbC8BZ+wa+CLuGoj3mWo3sqpooKHOgdRpZm99raPJY48M3WUP9iIDnJy8gDOYIAE5QAAABNBmiFsQz/+nhACs+6bIITZVtpIAAAAF0GaQjwhkymEM//+nhACoe6bGXJsq21NAAAAGEGaY0nhDyZTAhn//p4QAo/xOzrdAyQ0rAAAABlBmoRJ4Q8mUwIb//6nhAD3HGf6rfMfiDUhAAAAHEGapknhDyZTBRE8M//+nhAQvxa38yM9kFP4lW0AAAAQAZ7FakK/AewffLX9tny+YQAAABpBmsdJ4Q8mUwIb//6nhASvtVPPj/D6lOw6YQAAACBBmulJ4Q8mUwURPDf//qeEBEu1UZv5FH4a/4Ua3NoOmAAAABABnwhqQr8B3rL9UfMfi2NAAAAAGUGbCknhDyZTAhv//qeEAYLx0+l8UJDCj4EAAAAXQZstSeEPJlMCG//+p4QBf6DsNmPwFHwAAAARQZ9LRRE8K/8BLtnf9HJFUWUAAAAPAZ9sakK/AS7YjyYHr20PAAAAHEGbb0moQWiZTBTw3/6nhAGdi2MCET+TS7voVTEAAAAQAZ+OakK/AT+wjyXM+STmgQAAABxBm5FJ4QpSZTBSw3/+p4QFCFapj/UIr2D9MqpgAAAADwGfsGpCvwH5sR5MDX7LSQAAABhBm7RJ4Q6JlMCGf/6eEBQb3GhoH9tzDekAAAASQZ/SRRU8K/8CC2FedsF+RNuAAAAADwGf82pCvwILY7Jw2bTZMwAAABlBm/VJqEFomUwIZ//+nhAWK9xoaB/a4wz5AAAAGEGaFknhClJlMCGf/p4QGJc48Cb30RMMCAAAAB5BmjhJ4Q6JlMFNEwz//p4QHHzm+Ou7ehyrcVadIeEAAAAQAZ5XakK/AkiuDXHfiyu6YQAAABhBmllJ4Q8mUwIZ//6eEAfHoL9jAj6uw+YAAAAYQZp6SeEPJlMCGf/+nhAEcEOP54L+SGVVAAAAGUGam0nhDyZTAhn//p4QBJBDj3rbBzscj4AAAAAZQZq8SeEPJlMCG//+p4QBNB8xyTuNmCub0QAAABlBmt1J4Q8mUwIb//6nhAE8HzHJO42X/5rRAAAAGUGa/knhDyZTAh3//qmWAUdpCTa0hj7dNmAAAAARQZsCSeEPJlMCG//+p4QAAScAAAAMQZ8gRRE8L/8AALKBAAAAEAGfX3RCvwKwQBz9gW4sjYAAAAAQAZ9BakK/Aq7Wu6rGfRLRgQAAABtBm0ZJqEFomUwIZ//+nhAnpnSNgutziH93Qk4AAAAQQZ9kRREsL/8B6p0R9gXtqQAAAA8Bn4N0Qr8CsEAdB1LJaMEAAAAQAZ+FakK/Aq3miZEr5OSygQAAABlBm4dJqEFsmUwIb//+p4QLtsxvPgtnhYPTAAAAHUGbqUnhClJlMFFSwz/+nhAj2/v4G+tpodsFQ70gAAAADwGfyGpCvwJ1a8wHTYDlqQAAABlBm8pJ4Q6JlMCG//6nhAEt+On1HGhIcFlBAAAAGUGb60nhDyZTAhv//qeEAMe6tIIRP8ts9YAAAAAZQZoMSeEPJlMCG//+p4QAyPsH+E4LdCRxwAAAAB1Bmi9J4Q8mUwIb//6nhACCj5jyMT/IYg5aepPegQAAABJBnk1FETwr/wBsHVu5MHYCXCcAAAAQAZ5uakK/AGwdqW4bNqa4gQAAABpBmnJJqEFomUwIb//+p4QAgqATRREAci090AAAABBBnpBFESwr/wBsCQEOSslCAAAAEAGesWpCvwBpiZJpvpIOMvEAAAAbQZq2SahBbJlMCG///qeEAMzhyWbcC3x08jh4AAAAEEGe1EUVLC//AHmTo9FDp+QAAAAPAZ7zdEK/AEVtCAyS5amBAAAAEAGe9WpCvwCoWPHK/tw+ncAAAAAdQZr4SahBbJlMFEwz//6eEAMj6+/psoXLrZq2I+EAAAAQAZ8XakK/AKg1851oYXiqQQAAABlBmxlJ4QpSZTAhv/6nhAB/fYP8JwW6EllAAAAAGUGbOknhDomUwIb//qeEAFR91P1HGhIcUEEAAAAbQZtdSeEPJlMCGf/+nhAA2Pr79Nr3NER9UWOAAAAAEUGfe0URPCv/AC10o3mm96k7AAAADgGfnGpCvwAtbYx6IrmPAAAAGUGbnkmoQWiZTAhv//6nhAAi3x0x/h9W3GcAAAAZQZu/SeEKUmUwIb/+p4QAId8dPqONCQ5iwAAAABtBm8JJ4Q6JlMCG//6nhAAWP3U++GeJoLdIcfEAAAASQZ/gRRE8K/8AEdk+c6yfJ6OAAAAAEAGeAWpCvwARWWQw+gJB0jkAAAAaQZoDSahBaJlMCHf//qmWAAcn2l/O6QphKTAAAAAdQZonSeEKUmUwIb/+p4QACTfHT7tadHMssTI7RA8AAAAQQZ5FRTRML/8ABYqBFaUbjQAAAA8BnmR0Qr8AB2y/FwH5tsEAAAAQAZ5makK/AAeY1Dm+H8Sq0QAAABpBmmhJqEFomUwId//+qZYAAxntLwtQT+xGwAAAABZBmoxJ4QpSZTAh3/6plgAB6vhR92qgAAAADkGeqkU0TC//AAJLQDGhAAAAEAGeyXRCvwAEyVI78AH3UMAAAAAQAZ7LakK/AAds1Dn+ZbxgQAAAABNBmtBJqEFomUwId//+qZYAAJWBAAAADEGe7kURLC//AACygQAAABABnw10Qr8AB27FYvP4HOhBAAAAEAGfD2pCvwAHbNQ5/mW8YEAAAAASQZsUSahBbJlMCG///qeEAAEnAAAAFEGfMkUVLC//AAWtNnJm3DT1rroxAAAAEAGfUXRCvwAHmirVeBFeWYAAAAAPAZ9TakK/AAeYH9UigSwxAAAAEkGbWEmoQWyZTAhv//6nhAABJwAAABBBn3ZFFSwv/wAFryWzfpHWAAAAEAGflXRCvwAHmirVeBFeWYEAAAAPAZ+XakK/AAeYH9UigSwxAAAAGkGbmUmoQWyZTAh3//6plgADBe0vC1BP7EjAAAAAGkGbvUnhClJlMCG//qeEAAkqsCzbjN7qfHNRAAAAEEGf20U0TC//AAWKgQUobrgAAAAPAZ/6dEK/AAdCxWMIVflBAAAAEAGf/GpCvwAHbZg8mB6+XYEAAAAaQZv+SahBaJlMCHf//qmWAATAo51oer75ScAAAAAbQZoCSeEKUmUwIb/+p4QACXfHT7rSzNTbouOoAAAAEEGeIEU0TC//AAWtlioQbZEAAAAQAZ5fdEK/AAfFsDW0yh7lwAAAAA8BnkFqQr8AB8TUOhaN8sEAAAASQZpGSahBaJlMCG///qeEAAEnAAAADEGeZEURLC//AACygQAAABABnoN0Qr8AB8bFYvQS3OPBAAAAEAGehWpCvwAHxNQ5/o065YEAAAAZQZqHSahBbJlMCG///qeEAAZP2D17M+CMOwAAABtBmqtJ4QpSZTAhv/6nhAAJKPmqazbmvHT7Y/gAAAAVQZ7JRTRML/8ABYqBFPBhUEfu1e0sAAAAEAGe6HRCvwAE+TWjJLf7V4EAAAAQAZ7qakK/AAdtngXX9uIxwAAAABxBmu1JqEFomUwU8M/+nhAAOH65G7HDS3199v3gAAAAEAGfDGpCvwAL86p5MD18OYEAAAAYQZsOSeEKUmUwIb/+p4QAFq9E/1KQCulBAAAAG0GbL0nhDomUwIb//qeEABc8VpBCUQJ3/Rs0wQAAABtBm1JJ4Q8mUwIb//6nhAAXP0ZQtWfA5o4W/cAAAAARQZ9wRRE8K/8AEtlGPZqZ36gAAAAQAZ+RakK/ABJZXIq8AUB4gQAAABpBm5NJqEFomUwId//+qZYABMfjz9+yDcVd4AAAABtBm7dJ4QpSZTAh3/6plgADGe0v6/qtQshS6f4AAAAQQZ/VRTRML/8AA5/8PXXYwQAAAA8Bn/R0Qr8ABPk5QpNslpMAAAAPAZ/2akK/AATW1ru+77zBAAAAGkGb+kmoQWiZTAh3//6plgADAVIM0AekvtjRAAAAD0GeGEURLCv/AATWVwKewAAAAA0BnjlqQr8ABNg1h4z3AAAAE0GaPkmoQWyZTAh3//6plgAAlYAAAAAMQZ5cRRUsL/8AALKBAAAAEAGee3RCvwAHbsVi8/gc6EEAAAAPAZ59akK/AATJUjdZ6tE+AAAAGkGaYUmoQWyZTAh3//6plgADBe0vC1BP7EjAAAAAEkGen0UVLCv/AATWUAQCmAd3QQAAAA4BnqBqQr8ABNg0q6nVCQAAABJBmqVJqEFsmUwIb//+p4QAAScAAAAMQZ7DRRUsL/8AALKAAAAAEAGe4nRCvwAHQsVi8/gc6kEAAAAQAZ7kakK/AAdA1Dn+ZbxiwQAAABlBmuhJqEFsmUwIb//+p4QABfXVpBCJ/lxjAAAAEkGfBkUVLCv/AAdB+B0UtJYQvQAAABABnydqQr8AB21cGuPFW3UgAAAAEkGbLEmoQWyZTAhn//6eEAAEfAAAAAxBn0pFFSwv/wAAsoEAAAAPAZ9pdEK/AAT60d0dt8PHAAAAEAGfa2pCvwAEyVI72ePuoYAAAAAZQZttSahBbJlMCGf//p4QABdfdNjLk2Vf/QAAABlBm45J4QpSZTAhv/6nhAAI6gCzbbPs+e9BAAAAGEGbr0nhDomUwIb//qeEAAj3x0x/h9W4HwAAABtBm9JJ4Q8mUwIZ//6eEAA0shjn8Oc3m13jHuAAAAARQZ/wRRE8K/8ACxWO/6OSK68AAAAQAZ4RakK/AAsVhHkwPXxJgQAAABlBmhNJqEFomUwIb//+p4QADY+wevZnwRcBAAAAGEGaNEnhClJlMCG//qeEAA0/vs+pgEb5gAAAABlBmlVJ4Q6JlMCHf/6plgAER+PP37INxWHhAAAAKUGaeUnhDyZTAhv//qeEAAyfs0V8Cmn5B+BSIK/Aph5Eorz5/7Ln0ihAAAAAFEGel0URPC//AAdtOo6OJIfi6vjXAAAAEAGetnRCvwAGwk0InxZim+kAAAAQAZ64akK/AAo9kQm4z69XCAAAACxBmr1JqEFomUwIZ//+nhAAtnxO/BdBi+BTZPs/wKZriD4FEnmOD9ojyKfERwAAABFBnttFESwv/wAbpVo5tKmoEAAAABABnvp0Qr8AGIkteB0ynECBAAAADwGe/GpCvwAltrXd93v4wQAAABlBmv5JqEFsmUwIZ//+nhAAdH19/IkR9YXTAAAAGEGbH0nhClJlMCGf/p4QAEu+IedboGSLDAAAABhBmyBJ4Q6JlMCG//6nhAAS746Y/w+rbs0AAAAZQZtBSeEPJlMCG//+p4QAEm+jn3MihIdbQAAAAB1Bm2RJ4Q8mUwIb//6nhAAL/7B/Pg+JoLc8QdTlwQAAABJBn4JFETwr/wAJrJ851k9sxiUAAAAQAZ+jakK/AAlsshh9ASDvSQAAABpBm6VJqEFomUwIb//+p4QAB5/YP8JwW6F8wQAAABxBm8lJ4QpSZTAhv/6nhAAE/91Pu83X31sxQkCtAAAAEEGf50U0TC//AAL8HofZuiEAAAAQAZ4GdEK/AAP3wwGSW/28QAAAAA8BnghqQr8AA+JqHQtHH8AAAAAaQZoKSahBaJlMCG///qeEAAMn7MH8f4fVupcAAAAdQZosSeEKUmUwURLDf/6nhAAHPOOQ9VvmPwzZcWYAAAAQAZ5LakK/AAX52o5X9uJEQAAAABlBmk9J4Q6JlMCG//6nhAALV6J/qt8x+MnBAAAAEUGebUUVPCv/AAkuzv+jkivtAAAADgGejmpCvwAJLs9c16+1AAAAF0GakUmoQWiZTBTw3/6nhAARUfMeY8pgAAAAEAGesGpCvwAOKahz/Mt4WcAAAAASQZqzSeEKUmUwUsN//qeEAAEnAAAAEAGe0mpCvwAOKahz/Mt4WcAAAAASQZrVSeEOiZTBRMN//qeEAAEnAAAAEAGe9GpCvwAOKahz/Mt4WcEAAAATQZr3SeEPJlMFPDv//qmWAACVgAAAABABnxZqQr8ADimoc/zLeFnBAAAAFkGbG0nhDyZTAhv//qeEAAsfup+2W4EAAAAOQZ85RRE8L/8ABplW8TAAAAAQAZ9YdEK/AA4tisXn8Dl4wQAAAA8Bn1pqQr8ACRKkbrPVoJ4AAAAcQZtdSahBaJlMFPDf/qeEAAtnup+60szU26LhiQAAABABn3xqQr8ACW5o3mmKttbBAAAAGUGbYEnhClJlMCG//qeEAAdz2D/CcFuhf0AAAAAPQZ+eRTRMK/8ABiCWs4xAAAAAGAGfv2pCvwAD72hc8JSp//xCA5J/9JVgNQAAABJBm6RJqEFomUwIb//+p4QAAScAAAAMQZ/CRREsL/8AALKBAAAAEAGf4XRCvwAD2KG9l1X8XcAAAAAQAZ/jakK/AAPYob2K0fdmQQAAABJBm+hJqEFsmUwIX//+jLAABI0AAAAMQZ4GRRUsL/8AALKBAAAAEAGeJXRCvwAD2KG9l1X8XcEAAAAQAZ4nakK/AAPYob2K0fdmQAAAABpBmilLqEIQWyRGCCgH8gH9h4AhX/44QAARcAAAC2htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAKknRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACgptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAm1bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJdXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFQGN0dHMAAAAAAAAApgAAAAUAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAYAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAMAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFuQAAABcAAAAbAAAAHAAAAB0AAAAgAAAAFAAAAB4AAAAkAAAAFAAAAB0AAAAbAAAAFQAAABMAAAAgAAAAFAAAACAAAAATAAAAHAAAABYAAAATAAAAHQAAABwAAAAiAAAAFAAAABwAAAAcAAAAHQAAAB0AAAAdAAAAHQAAABUAAAAQAAAAFAAAABQAAAAfAAAAFAAAABMAAAAUAAAAHQAAACEAAAATAAAAHQAAAB0AAAAdAAAAIQAAABYAAAAUAAAAHgAAABQAAAAUAAAAHwAAABQAAAATAAAAFAAAACEAAAAUAAAAHQAAAB0AAAAfAAAAFQAAABIAAAAdAAAAHQAAAB8AAAAWAAAAFAAAAB4AAAAhAAAAFAAAABMAAAAUAAAAHgAAABoAAAASAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABgAAAAUAAAAEwAAABYAAAAUAAAAFAAAABMAAAAeAAAAHgAAABQAAAATAAAAFAAAAB4AAAAfAAAAFAAAABQAAAATAAAAFgAAABAAAAAUAAAAFAAAAB0AAAAfAAAAGQAAABQAAAAUAAAAIAAAABQAAAAcAAAAHwAAAB8AAAAVAAAAFAAAAB4AAAAfAAAAFAAAABMAAAATAAAAHgAAABMAAAARAAAAFwAAABAAAAAUAAAAEwAAAB4AAAAWAAAAEgAAABYAAAAQAAAAFAAAABQAAAAdAAAAFgAAABQAAAAWAAAAEAAAABMAAAAUAAAAHQAAAB0AAAAcAAAAHwAAABUAAAAUAAAAHQAAABwAAAAdAAAALQAAABgAAAAUAAAAFAAAADAAAAAVAAAAFAAAABMAAAAdAAAAHAAAABwAAAAdAAAAIQAAABYAAAAUAAAAHgAAACAAAAAUAAAAFAAAABMAAAAeAAAAIQAAABQAAAAdAAAAFQAAABIAAAAbAAAAFAAAABYAAAAUAAAAFgAAABQAAAAXAAAAFAAAABoAAAASAAAAFAAAABMAAAAgAAAAFAAAAB0AAAATAAAAHAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2XE5XcX8CNu",
        "colab_type": "text"
      },
      "source": [
        "Note : The results seems quite poor during the training because of the penalty added for exploration. But the performance reached are very satisfying. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UupcElN2VNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "bc546343-dbc9-429c-9a16-f687f0973c9a"
      },
      "source": [
        "# Evaluation\n",
        "epochs_test = 11\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 14.5/0. Average score (14.5)\n",
            "Win/lose count 15.0/0. Average score (14.75)\n",
            "Win/lose count 18.5/0. Average score (16.0)\n",
            "Win/lose count 2.0/0. Average score (12.5)\n",
            "Win/lose count 15.0/1.0. Average score (12.8)\n",
            "Win/lose count 19.0/1.0. Average score (13.666666666666666)\n",
            "Win/lose count 17.0/0. Average score (14.142857142857142)\n",
            "Win/lose count 10.5/1.0. Average score (13.5625)\n",
            "Win/lose count 14.0/1.0. Average score (13.5)\n",
            "Win/lose count 20.0/3.0. Average score (13.85)\n",
            "Win/lose count 13.0/1.0. Average score (13.681818181818182)\n",
            "Final score: 13.681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn7ZLRFt2VNt",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NsHmNFq2VNv",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}